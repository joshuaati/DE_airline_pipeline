{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import bz2\n",
    "import requests\n",
    "from typing import Tuple\n",
    "from google.cloud import storage\n",
    "from datetime import timedelta\n",
    "from typing import List, Tuple\n",
    "from prefect import flow, task\n",
    "from prefect.tasks import task_input_hash, exponential_backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(url: str, output_dir: str) -> str:\n",
    "\n",
    "    output_dir = os.path.abspath(output_dir)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    file_path = os.path.join(output_dir, os.path.basename(url))\n",
    "\n",
    "    response = requests.get(url)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    return file_path\n",
    "\n",
    "def extract_data(file_path: str, output_dir: str) -> Tuple[str, str]:\n",
    "\n",
    "    output_dir = os.path.abspath(output_dir)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "\n",
    "    extracted_files = []\n",
    "    for root, _, files in os.walk(output_dir):\n",
    "        for file in files:\n",
    "            extracted_files.append(os.path.join(root, file))\n",
    "\n",
    "    return tuple(extracted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/workspaces/DE_airline_on_time/data/yellow.zip',\n",
       " '/workspaces/DE_airline_on_time/data/nyc-tlc-data-yellow/README.md')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_data(download_data('https://github.com/DataTalksClub/nyc-tlc-data/archive/refs/tags/yellow.zip', 'data'), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/1987.csv.bz2', 'data/1988.csv.bz2', 'data/1989.csv.bz2', 'data/1990.csv.bz2', 'data/1991.csv.bz2', 'data/1992.csv.bz2', 'data/1993.csv.bz2', 'data/1994.csv.bz2', 'data/1995.csv.bz2', 'data/1996.csv.bz2', 'data/1997.csv.bz2', 'data/1998.csv.bz2', 'data/1999.csv.bz2', 'data/2000.csv.bz2', 'data/2001.csv.bz2', 'data/2002.csv.bz2', 'data/2003.csv.bz2', 'data/2004.csv.bz2', 'data/2005.csv.bz2', 'data/2006.csv.bz2', 'data/2007.csv.bz2', 'data/2008.csv.bz2', 'data/airports.csv', 'data/carriers.csv', 'data/plane-data.csv', 'data/variable-descriptions.csv')\n"
     ]
    }
   ],
   "source": [
    "extracted_files = []\n",
    "for root, _, files in os.walk('data'):\n",
    "    for file in files:\n",
    "        extracted_files.append(os.path.join(root, file))\n",
    "\n",
    "print(tuple(extracted_files))\n",
    "extracted_files = tuple(extracted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def compress_files(extracted_files: Tuple[str, ...], output_dir: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    This function compresses extracted CSV files in .bz2 format into .gz format and saves them in the specified output\n",
    "    directory. If the CSV file is encoded with 'latin_1', it will first be decoded before being compressed. Additionally,\n",
    "    any occurrences of the characters '-', 'ä', 'æ', and 'â' in the 'TailNum' column will be stripped of whitespace.\n",
    "\n",
    "    Parameters:\n",
    "    extracted_files (Tuple[str, ...]): A tuple of file paths to CSV files in .bz2 format to be compressed.\n",
    "    output_dir (str): The directory in which the compressed files will be saved.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[str, str]: A tuple of file paths to the compressed files in the output directory.\n",
    "\n",
    "    \"\"\"\n",
    "    for file_path in extracted_files:\n",
    "        # Check if the file is in .bz2 format\n",
    "        if file_path.endswith('.bz2'):\n",
    "            compressed_file_path = file_path[:-4] + '.gz'\n",
    "            try:\n",
    "                # Try to read the file using the default encoding ('utf-8')\n",
    "                df = pd.read_csv(file_path)\n",
    "                # Compress the file and save it in the output directory\n",
    "                df.to_csv(compressed_file_path, index=False, compression='gzip')\n",
    "                # Remove the original file\n",
    "                os.remove(file_path)\n",
    "            except UnicodeDecodeError:\n",
    "                # If the default encoding fails, try reading the file using 'latin_1' encoding\n",
    "                df = pd.read_csv(file_path, encoding='latin_1')\n",
    "                df['TailNum'] = df['TailNum'].str.strip('-äæâ')\n",
    "                # Compress the file and save it in the output directory\n",
    "                df.to_csv(compressed_file_path, index=False, compression='gzip')\n",
    "                # Remove the original file\n",
    "                os.remove(file_path)\n",
    "    \n",
    "    # Collect all file paths in the output directory\n",
    "    all_files = []\n",
    "    for root, _, files in os.walk(output_dir):\n",
    "        for file in files:\n",
    "            all_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # Return the file paths as a tuple\n",
    "    return tuple(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2001.csv.bz2', encoding='latin_1')\n",
    "df['TailNum'] = df['TailNum'].str.strip('-äæâ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/2001.csv.bz2', encoding='latin_1')\n",
    "df2['TailNum'] = df2['TailNum'].str.strip('-äæâ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime',\n",
       "       'CRSDepTime', 'ArrTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum',\n",
       "       'TailNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay',\n",
       "       'DepDelay', 'Origin', 'Dest', 'Distance', 'TaxiIn', 'TaxiOut',\n",
       "       'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay',\n",
       "       'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "äNKNOæ    176811\n",
       "-N823A      3982\n",
       "-N819A      3850\n",
       "-N810A      3755\n",
       "-N916D      3631\n",
       "           ...  \n",
       "N000A1         1\n",
       "N661äâ         1\n",
       "N662äâ         1\n",
       "N7BäA1         1\n",
       "N668äâ         1\n",
       "Name: TailNum, Length: 4561, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['TailNum'] = df2['TailNum'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            N700\n",
       "1            N713\n",
       "2            N702\n",
       "3            N701\n",
       "4            N768\n",
       "            ...  \n",
       "5967775     N914D\n",
       "5967776     N913D\n",
       "5967777     N910D\n",
       "5967778    N906D1\n",
       "5967779    N905D1\n",
       "Name: TailNum, Length: 5967780, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['TailNum'] = df2['TailNum'].str.strip('-äæâ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime',\n",
       "       'ArrTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum', 'TailNum',\n",
       "       'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay',\n",
       "       'DepDelay', 'Origin', 'Dest', 'Distance', 'TaxiIn', 'TaxiOut',\n",
       "       'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay',\n",
       "       'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.TailNum.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/1987.csv.bz2')\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.to_csv('data/1987.csv.gz', compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_individual_files(extracted_files: Tuple[str, ...]) -> Tuple[str, ...]:\n",
    "    new_extracted_files = []\n",
    "    for file_path in extracted_files:\n",
    "        if file_path.endswith('.bz2'):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                content = f.read()\n",
    "            decompressed_content = bz2.decompress(content)\n",
    "            new_file_path = file_path[:-4]  # remove .bz2 extension\n",
    "            with open(new_file_path, 'wb') as f:\n",
    "                f.write(decompressed_content)\n",
    "            new_extracted_files.append(new_file_path)\n",
    "        else:\n",
    "            new_extracted_files.append(file_path)\n",
    "    print((new_extracted_files))\n",
    "    return (new_extracted_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/1987.csv', 'data/1988.csv', 'data/1989.csv', 'data/1990.csv', 'data/1991.csv', 'data/1992.csv', 'data/1993.csv', 'data/1994.csv', 'data/1995.csv', 'data/1996.csv', 'data/1997.csv', 'data/1998.csv', 'data/1999.csv', 'data/2000.csv', 'data/2001.csv', 'data/2002.csv', 'data/2003.csv', 'data/2004.csv', 'data/2005.csv', 'data/2006.csv', 'data/2007.csv', 'data/2008.csv', 'data/airports.csv', 'data/carriers.csv', 'data/plane-data.csv', 'data/variable-descriptions.csv']\n"
     ]
    }
   ],
   "source": [
    "extracted_files = ('data/1987.csv.bz2', 'data/1988.csv.bz2', 'data/1989.csv.bz2', 'data/1990.csv.bz2', 'data/1991.csv.bz2', 'data/1992.csv.bz2', 'data/1993.csv.bz2', 'data/1994.csv.bz2', 'data/1995.csv.bz2', 'data/1996.csv.bz2', 'data/1997.csv.bz2', 'data/1998.csv.bz2', 'data/1999.csv.bz2', 'data/2000.csv.bz2', 'data/2001.csv.bz2', 'data/2002.csv.bz2', 'data/2003.csv.bz2', 'data/2004.csv.bz2', 'data/2005.csv.bz2', 'data/2006.csv.bz2', 'data/2007.csv.bz2', 'data/2008.csv.bz2', 'data/airports.csv', 'data/carriers.csv', 'data/plane-data.csv', 'data/variable-descriptions.csv')\n",
    "individual_files = extract_individual_files(extracted_files)\n",
    "# compress_file(individual_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompress_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1987.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1988.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1989.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1990.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1991.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1992.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1993.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1994.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1995.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1996.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1997.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1998.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/1999.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/2000.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/2001.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/2002.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/2003.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/2004.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/2005.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/2006.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/2007.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/2008.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/airports.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/carriers.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/plane-data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/variable-descriptions.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 23\u001b[0m, in \u001b[0;36mcompress_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Open the input and output files\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(files, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_in, gzip\u001b[38;5;241m.\u001b[39mopen(compressed_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_out:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Copy the contents of the input file to the output file\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mf_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwritelines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Delete the original file\u001b[39;00m\n\u001b[1;32m     26\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(files)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/gzip.py:289\u001b[0m, in \u001b[0;36mGzipFile.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    286\u001b[0m     length \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mnbytes\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m length \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfileobj\u001b[39m.\u001b[39mwrite(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompress\u001b[39m.\u001b[39;49mcompress(data))\n\u001b[1;32m    290\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m length\n\u001b[1;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrc \u001b[39m=\u001b[39m zlib\u001b[39m.\u001b[39mcrc32(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrc)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compress_file(['data/1987.csv', 'data/1988.csv', 'data/1989.csv', 'data/1990.csv', 'data/1991.csv', 'data/1992.csv', 'data/1993.csv', 'data/1994.csv', 'data/1995.csv', 'data/1996.csv', 'data/1997.csv', 'data/1998.csv', 'data/1999.csv', 'data/2000.csv', 'data/2001.csv', 'data/2002.csv', 'data/2003.csv', 'data/2004.csv', 'data/2005.csv', 'data/2006.csv', 'data/2007.csv', 'data/2008.csv', 'data/airports.csv', 'data/carriers.csv', 'data/plane-data.csv', 'data/variable-descriptions.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
